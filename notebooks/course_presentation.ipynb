{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation seminar 2: Foundations of Conformal and Venn Prediction with applications 151124\n",
    "\n",
    "I am working on a python package for online conformal prediction. The motivation was that we use conformalised ridge regression and test martingales in some of the projects I am working on with industrial partners, and I have not found any packages for online conformal prediction. Since we had the nice one-nearest neighbours example in the introductory lecture, I decided to add this algorithm to the package. Coincedentally, we just managed to ready a release of a minimal version of the package yesterday, which can be found on PiPy https://pypi.org/project/online-cp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rnd_gen = np.random.default_rng(2024)\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from online_cp import ConformalNearestNeighboursClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The example from day 1\n",
    "\n",
    "$(3,+1),(-2,-1),(-1,-1),(1,+1),(2,+1),\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([3, -2, -1, 1, 2]).reshape(-1,1)\n",
    "Y = np.array([1, -1, -1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a conformal predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ConformalNearestNeighboursClassifier(label_space=np.unique(Y), rnd_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and process the examples one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "Gamma, p_values = cp.predict(X[i], epsilon=0.1, return_p_values=True, verbose=100)\n",
    "print(f'Realised p-values: {p_values}')\n",
    "print(f'Prediction set {Gamma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example given, we had\n",
    "\n",
    "$p(+1) = \\tau_1$\n",
    "\n",
    "$p(-1) = \\tau_1$\n",
    "\n",
    "Which agrees with the above. In this implementation, the distance is set to $\\infty$ if there is no example with the same/different label. In the example given, it was 100.\n",
    "\n",
    "\n",
    "Next, we learn the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.learn_one(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the second object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "Gamma, p_values = cp.predict(X[i], epsilon=0.1, return_p_values=True, verbose=100)\n",
    "print(f'Realised p-values: {p_values}')\n",
    "print(f'Prediction set {Gamma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example given, we had\n",
    "\n",
    "$p(+1) = \\tau_2$\n",
    "\n",
    "$p(-1) = \\tau_2$\n",
    "\n",
    "which again agrees with the above.\n",
    "\n",
    "We learn the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.learn_one(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the third object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "Gamma, p_values = cp.predict(X[i], epsilon=0.1, return_p_values=True, verbose=100)\n",
    "print(f'Realised p-values: {p_values}')\n",
    "print(f'Prediction set {Gamma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example given, we had\n",
    "\n",
    "$p(+1) = \\dfrac{1+\\tau_3}{3}$\n",
    "\n",
    "$p(-1) = \\dfrac{1+\\tau_3}{3}$\n",
    "\n",
    "which again agrees with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.learn_one(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict fourth object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "\n",
    "Gamma, p_values = cp.predict(X[i], epsilon=0.1, return_p_values=True, verbose=100)\n",
    "print(f'Realised p-values: {p_values}')\n",
    "print(f'Prediction set {Gamma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example given, we had\n",
    "\n",
    "$p(+1) = \\dfrac{\\tau_4}{4}$\n",
    "\n",
    "$p(-1) = \\dfrac{1+\\tau_4}{4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.learn_one(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict fifth and final object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "\n",
    "Gamma, p_values = cp.predict(X[i], epsilon=0.1, return_p_values=True, verbose=100)\n",
    "print(f'Realised p-values: {p_values}')\n",
    "print(f'Prediction set {Gamma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example given, we had\n",
    "\n",
    "$p(+1) = \\dfrac{2+2\\tau_5}{5}$\n",
    "\n",
    "$p(-1) = \\dfrac{\\tau_5}{5}$\n",
    "\n",
    "However, if we look carefully at the nonconformity scores, it seems that we have a disagreement between the example and $\\alpha_3$ for the hypothesis $y=+1$. It turns out that this is a typo in the slides, because $z_3=(-1, -1)$, and looking at the data sequence with the hypothesised last label set to $+1$ (which happens to be the true value), it is\n",
    "$$\n",
    "    (3, +1), (-2, -1), (-1, -1), (1, +1), (2, +1)\n",
    "$$\n",
    "The nearest neighbour of $(-1, -1)$ with the same label is $(-2,-1)$, and the distance is 1. The nearest neighbour with another label is $(1,+1)$, and the distance is 2. Thus $\\alpha_3=1/2$ (the slide has $\\alpha_3=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the order\n",
    "The p-value of the true hypothesis changes if the last example is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    cp = ConformalNearestNeighboursClassifier(rnd_state=2024)\n",
    "    cp.learn_initial_training_set(X=np.delete(X, i).reshape(-1,1), y=np.delete(Y, i))\n",
    "    print(f'Last example: ({X[i][0]}, {Y[i]})')\n",
    "    cp.predict(X[i], verbose=100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a mess, so let's make a table\n",
    "|Last|$\\alpha_5$|$p(y_5)$|Distribution|\n",
    "|-----|----|----|---|\n",
    "|$(3,+1)$|1/4|$\\dfrac{4+1\\tau_5}{5}$|Uniform 0.8, 1\n",
    "|$(-2,-1)$|1/3|$\\dfrac{2+2\\tau_5}{5}$| Uniform 0.4, 0.8\n",
    "|$(-1,-1)$|1/2|$\\dfrac{2\\tau_5}{5}$|Uniform 0, 0.4\n",
    "|$(1,+1)$|1/2|$\\dfrac{2\\tau_5}{5}$|Uniform 0, 0.4\n",
    "|$(2,+1)$|1/3|$\\dfrac{2+2\\tau_5}{5}$|Uniform 0.4, 0.8\n",
    "\n",
    "This table is different from the slides, which is probably due to the previously mentioned typo. However, the overall mixture is still uniform on $[0,1]$. We can check this statistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly draw the last example and compute the p-value for the true hypothesis\n",
    "We could do a proper statistical test, but let's be satisfied for now with a historam. Later in the course, the obvious thing to do is to use a conformal test martingale to test the hypothesis that the p-values are uniformly distributed on $[0,1]$. The package has functinoality for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "rnd_indices = rnd_gen.integers(low=0, high=5, size=N)\n",
    "rnd_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realised_p_values = np.empty(N)\n",
    "for i, j in enumerate(rnd_indices):\n",
    "    cp = ConformalNearestNeighboursClassifier()\n",
    "    cp.learn_initial_training_set(X=np.delete(X, j).reshape(-1,1), y=np.delete(Y, j))\n",
    "    _, p_values = cp.predict(X[j], return_p_values=True)\n",
    "    realised_p_values[i] = p_values[Y[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(realised_p_values, density=True)\n",
    "plt.title('Looks uniform enough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup (if there is time)\n",
    "\n",
    "Just to illustrate the algorithm in action on a larger dataset, we generate a three class classification problem with two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "X, Y = make_classification(n_samples=N, n_features=2, n_informative=2, n_redundant=0, \n",
    "                           n_classes=3, n_clusters_per_class=1, random_state=2024)\n",
    "\n",
    "# Create a scatter plot with different symbols for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define different markers for each class\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# Plot each class with a different marker\n",
    "for label, marker, color in zip(np.unique(Y), markers, colors):\n",
    "    plt.scatter(X[Y == label, 0], X[Y == label, 1], label=f'Class {label}', marker=marker, color=color, edgecolor='k')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.title('Synthetic Classification Dataset with 3 Classes')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the whole dataset and evaluate the performance of our conformal predictor using the efficiency criteria observed excess (OE) and observed fuzziness (OF). These are described in chapter 3 among some others, but these are listed as preferred, as they are conditionally proper (using the conditional probability as conformity measure is optimal).\n",
    "\n",
    "$OE_n := |\\Gamma^{\\epsilon}_n\\backslash\\{y_n\\}|$ is the number of labels included apart from the correct one, and \n",
    "\n",
    "$OF_n := \\sum_{y\\in\\boldsymbol{Y}\\backslash\\{y_n\\}}p^y_n$ is the sum of the p-values of the false labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "cp = ConformalNearestNeighboursClassifier(label_space=np.unique(Y), rnd_state=2024)\n",
    "\n",
    "res = np.zeros(shape=(Y.shape[0], 5))\n",
    "\n",
    "for i, (object, label) in tqdm(enumerate(zip(X, Y)), total=Y.shape[0], desc='Running online conformal prediction'):\n",
    "\n",
    "    # Reality outputs object\n",
    "    x = object\n",
    "\n",
    "    # Forecaster outputs prediction set\n",
    "    # Computing distances is needed both for prediction and learning. Returning the updated distance matrix saves some computation time\n",
    "    Gamma, p_values, D = cp.predict(x, epsilon=epsilon, return_p_values=True, return_update=True) \n",
    "\n",
    "    # Reality outputs label\n",
    "    y = label\n",
    "\n",
    "    # Check error\n",
    "    err = cp.err(Gamma, label)\n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(x, y, D)\n",
    "    \n",
    "    # Prefferred efficiency criteria\n",
    "\n",
    "    # Observed excess\n",
    "    cp.oe(Gamma, y)\n",
    "\n",
    "    # Observed fuzziness\n",
    "    cp.of(p_values, y)\n",
    "\n",
    "    # For plotting\n",
    "    res[i, 0] = cp.OE\n",
    "    res[i, 1] = cp.OF\n",
    "    res[i, 2] = cp.Err\n",
    "    res[i, 3] = y\n",
    "    res[i, 4] = err\n",
    "\n",
    "print(f'Average error: {cp.Err/Y.shape[0]}')\n",
    "print(f'Average observed excess: {cp.OE/Y.shape[0]}')\n",
    "print(f'Average observed fuzziness: {cp.OF/Y.shape[0]}')\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(16,6))\n",
    "axs[0].plot(res[:, 2], label='Cummulative error')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(res[:, 0], label='Cummulative OE')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(res[:, 1], label='Cummulative OF')\n",
    "axs[2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the plot of the examples, the red ones (class 0) should be easier to predict, and indeed, the error rate for class 0 is significantly smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'Error rate for label {i}: {res[np.where(res[:, 3]==i)[0]][:, 4].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "* Is there some fundamental reason to limit the number of neighbours considered to one? Could we not have the same sort of nonconformity measure with the mean or median of $k>1$ neighbours?\n",
    "* The book proves the uniform distribution of the p-values in the setting of a general online compression model, which is nice, but I wonder if there is some simpler proof if we limit ourselves to the exchangeability model? I have not looked into it myself so far."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlineCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
