{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal classification\n",
    "We create a synthetic classification dataset with three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "N = 250\n",
    "\n",
    "X, y = make_classification(n_samples=N, n_features=2, n_informative=2, n_redundant=0, \n",
    "                           n_classes=3, n_clusters_per_class=1, random_state=2024)\n",
    "\n",
    "\n",
    "# Create a scatter plot with different symbols for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define different markers for each class\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# Plot each class with a different marker\n",
    "for label, marker, color in zip(np.unique(y), markers, colors):\n",
    "    plt.scatter(X[y == label, 0], X[y == label, 1], label=f'Class {label}', marker=marker, color=color, edgecolor='k')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.title('Synthetic Classification Dataset with 3 Classes')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp import ConformalNearestNeighboursClassifier\n",
    "\n",
    "cp = ConformalNearestNeighboursClassifier(k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To just test the conformal predictor on the dataset, we use the .process_dataset method. We can specify a significance level, an initial training set size, and we can return the prediction sets and the cummulative efficeincy criteria. The object returned is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cp.process_dataset(X=X, y=y, epsilon=0.1, init_train=0, return_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the key 'Efficiency' are the efficiency criteria and the average error, as well as the time it took to process the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Efficiency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction sets are arrays with the included labels specified. An empty array indicate an empty prediciton set. These are returned only if specified with the return_results keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Prediction sets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining keys, which are only present if return_result is set to True, give the cummulative error  and efficiency criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(16,6))\n",
    "axs[0].plot(result['Cummulative Err'], label='Cummulative error')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(result['Cummulative OE'], label='Cummulative OE')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(result['Cummulative OF'], label='Cummulative OF')\n",
    "axs[2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce the .process_dataset manually, we can do the following. Let's use the first 100 examples as initial training set. We can also use the p-values to test the exchangeability assumption with a test martingale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(shape=(y.shape[0], 3))\n",
    "prediction_sets = {}\n",
    "\n",
    "init_train = 100\n",
    "X_train = X[:init_train]\n",
    "y_train = y[:init_train]\n",
    "X_run = X[init_train:]\n",
    "y_run = y[init_train:]\n",
    "\n",
    "cp = ConformalNearestNeighboursClassifier(k=1, label_space=np.unique(y))\n",
    "\n",
    "from online_cp import PluginMartingale\n",
    "\n",
    "martingale = PluginMartingale()\n",
    "\n",
    "\n",
    "cp.learn_initial_training_set(X=X_train, y=y_train)\n",
    "\n",
    "for i, (obj, lab) in enumerate(zip(X_run, y_run)):\n",
    "    \n",
    "    # Make prediction\n",
    "    Gamma, p_values, D = cp.predict(obj, epsilon=0.1, return_p_values=True, return_update=True) \n",
    "\n",
    "    # Check error\n",
    "    cp.err(Gamma, lab)\n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(obj, lab, D)\n",
    "\n",
    "    # Update martingale\n",
    "    martingale.update_martingale_value(p_values[lab])\n",
    "\n",
    "    # Prefferred efficiency criteria\n",
    "\n",
    "    # Observed excess\n",
    "    cp.oe(Gamma, lab)\n",
    "\n",
    "    # Observed fuzziness\n",
    "    cp.of(p_values, lab)\n",
    "\n",
    "    res[i, 0] = cp.OE\n",
    "    res[i, 1] = cp.OF\n",
    "    res[i, 2] = cp.Err\n",
    "    prediction_sets[i] = Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(martingale.martingale_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal regression\n",
    "We make a synthetic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_gen = np.random.default_rng(2024)\n",
    "\n",
    "N = 1000\n",
    "X = rnd_gen.normal(loc=0, scale=1, size=(N, 4))\n",
    "beta = np.array([2, 1, 0, 0])\n",
    "y = X @ beta + rnd_gen.normal(loc=0, scale=1, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If autotune is set to True, the ridge parameter is optimised using generalised cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp import ConformalRidgeRegressor\n",
    "\n",
    "cp = ConformalRidgeRegressor(autotune=True)\n",
    "\n",
    "result = cp.process_dataset(X=X, y=y, epsilon=0.1, init_train=int(N/2), return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Efficiency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediciton sets are now tuples with the first value indicating the lower bound of the interval, and the second value indicating the upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Prediction sets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(10,6))\n",
    "axs[0].plot(result['Cummulative Err'], label='Cummulative error')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(result['Width'], label='Width')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can do the same manually, but now, let us introcude a change point after the initial training set, and see if we can detect it with a conformal test martingale.\n",
    "\n",
    "The computations for predicting a set, and learning the new label share many steps, so we can save some time by returning a precomputed object that can be passed to the learn_one and compute_smoothed_p_value methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = np.array([2, 1, 0, 0])\n",
    "beta2 = np.array([0, 0, 1, 2])\n",
    "\n",
    "Y1 = X[:int(N/2)] @ beta1 + rnd_gen.normal(loc=0, scale=1, size=int(N/2))\n",
    "Y2 = X[int(N/2):N] @ beta2 + rnd_gen.normal(loc=0, scale=1, size=int(N/2))\n",
    "y = np.concatenate([Y1, Y2])\n",
    "\n",
    "init_train = int(N/2)\n",
    "\n",
    "X_train = X[:init_train]\n",
    "y_train = y[:init_train]\n",
    "X_run = X[init_train:]\n",
    "y_run = y[init_train:]\n",
    "\n",
    "Err = 0\n",
    "Width = 0\n",
    "\n",
    "X_train = X[:init_train]\n",
    "y_train = y[:init_train]\n",
    "X_run = X[init_train:]\n",
    "y_run = y[init_train:]\n",
    "\n",
    "res = np.zeros(shape=(y_run.shape[0], 2))\n",
    "prediction_sets = {}\n",
    "\n",
    "cp = ConformalRidgeRegressor(autotune=True)\n",
    "\n",
    "# Exchangeability assumption can be discarded with conficence 0.99 if the martingale calue exceeds 100\n",
    "# If warnings are set to True, the martingale will issue a user warning once it grows beyind the warning level.\n",
    "martingale = PluginMartingale(warning_level=100, warnings=False) \n",
    "\n",
    "cp.learn_initial_training_set(X=X_train, y=y_train)\n",
    "\n",
    "for i, (obj, lab) in enumerate(zip(X_run, y_run)):\n",
    "    \n",
    "    # Make prediction\n",
    "    Gamma, precomputed = cp.predict(obj, epsilon=0.1, return_update=True) \n",
    "\n",
    "    # Check error\n",
    "    Err += cp.err(Gamma, lab)\n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(obj, lab, precomputed)\n",
    "\n",
    "    # Compute smoothed p-value \n",
    "    p = cp.compute_p_value(x=obj, y=lab, precomputed=precomputed)\n",
    "    \n",
    "    # Update martingale\n",
    "    martingale.update_martingale_value(p)\n",
    "    \n",
    "    # Width of interval\n",
    "    width = cp.width(Gamma)\n",
    "    Width += width\n",
    "\n",
    "    res[i, 0] = Err\n",
    "    res[i, 1] = width\n",
    "    prediction_sets[i] = Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(martingale.martingale_values))\n",
    "plt.axhline(y=np.log(100), linestyle='--', color='red', label='Warning level')\n",
    "plt.legend()\n",
    "plt.title('Log martingale values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
