{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a synthetic classification dataset with three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "N = 500\n",
    "\n",
    "X, y = make_classification(n_samples=N, n_features=2, n_informative=2, n_redundant=0, \n",
    "                           n_classes=3, n_clusters_per_class=1, random_state=2024)\n",
    "\n",
    "\n",
    "# Create a scatter plot with different symbols for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define different markers for each class\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# Plot each class with a different marker\n",
    "for label, marker, color in zip(np.unique(y), markers, colors):\n",
    "    plt.scatter(X[y == label, 0], X[y == label, 1], label=f'Class {label}', marker=marker, color=color, edgecolor='k')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.title('Synthetic Classification Dataset with 3 Classes')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a conformal predictor and evaluate the running results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp import ConformalNearestNeighboursClassifier\n",
    "from online_cp import Evaluation, Err, OF, OE\n",
    "cp = ConformalNearestNeighboursClassifier(k=1, label_space=np.unique(y))\n",
    "\n",
    "metrics = Evaluation(err=Err, oe=OE, of=OF)\n",
    "\n",
    "for i, (obj, lab) in enumerate(zip(X, y)):\n",
    "    \n",
    "    # Make prediction\n",
    "    Gamma, p_values, D = cp.predict(obj, epsilon=0.1, return_p_values=True, return_update=True) \n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(obj, lab, D)\n",
    "\n",
    "    metrics.update(y=lab, Gamma=Gamma, p_values=p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_cumulative_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a ConformalPredictionSet. It is represented as an array with the included labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_gen = np.random.default_rng(2024)\n",
    "\n",
    "N = 1000\n",
    "X = rnd_gen.normal(loc=0, scale=1, size=(N, 4))\n",
    "beta = np.array([2, 1, 0, 0])\n",
    "y = X @ beta + rnd_gen.normal(loc=0, scale=1, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a conformal predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp import ConformalRidgeRegressor\n",
    "from online_cp import WinklerScore, Width\n",
    "\n",
    "cp = ConformalRidgeRegressor(a=0.001)\n",
    "\n",
    "metrics = Evaluation(err=Err, winkler=WinklerScore, width=Width)\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "# Ensure that we can get informative prediction sets\n",
    "X_init_train = X[:int(np.ceil(2/epsilon))]\n",
    "y_init_train = y[:int(np.ceil(2/epsilon))]\n",
    "\n",
    "X_process = X[int(np.ceil(2/epsilon)):]\n",
    "y_process = y[int(np.ceil(2/epsilon)):]\n",
    "\n",
    "cp.learn_initial_training_set(X_init_train, y_init_train)\n",
    "\n",
    "for obj, lab in zip(X_process, y_process):\n",
    "    \n",
    "    # Make prediction\n",
    "    Gamma, precomputed = cp.predict(obj, epsilon=epsilon, return_update=True) \n",
    "    # To avoid repeating computations, we return some precomputed arrays if return_update=True\n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(obj, lab, precomputed)\n",
    "    # We do not have to invert a matrix at each step n. The hat matrix can be efficiently updaten online using the Sherman-Morrison formula\n",
    "\n",
    "    # Update efficiency criteria\n",
    "    metrics.update(y=lab, Gamma=Gamma, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_cumulative_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a conformal regressor is a ConformalPredictionInterval, which is represented as a tuple with the interval boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma.width()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal predictive system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a conformal predictive system, and run it on the synthetic regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp import RidgePredictionMachine, CRPS\n",
    "\n",
    "cps = RidgePredictionMachine(a=0.001)\n",
    "\n",
    "cps.learn_initial_training_set(X_init_train, y_init_train)\n",
    "\n",
    "metrics = Evaluation(crps=CRPS)\n",
    "\n",
    "for obj, lab in zip(X_process, y_process):\n",
    "    tau = np.random.uniform(0, 1)\n",
    "    \n",
    "    # Compute CPD\n",
    "    cpd, precomputed = cps.predict_cpd(x=obj, return_update=True) \n",
    "    # To avoid repeating computations, we return some precomputed arrays if return_update=True\n",
    "\n",
    "    # Learn the label\n",
    "    cps.learn_one(x=obj, y=lab, precomputed=precomputed)\n",
    "\n",
    "    # Update efficiency\n",
    "    metrics.update(y=lab, cpd=cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_cumulative_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a conformal predictive system is a conformal predictive function (CPD), a callable function. To better illustrate its properties, retrain with a smaller training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = RidgePredictionMachine(a=0.001)\n",
    "\n",
    "cps.learn_initial_training_set(X=X[:100], y=y[:100])\n",
    "\n",
    "cpd = cps.predict_cpd(X_process[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a CPD with a potential label outputs the upper and lower value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd(y=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also passing a random number $\\tau$, generated independently form everyhing else, outputs the smoothed p-value of the potential label $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd(y=-2, tau=rnd_gen.uniform(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can illustrate the CPD by plotting the lower and upper distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a random number $\\tau$ plots the convex combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd.plot(tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CPD can be used to construct prediction intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd.predict_set(tau=tau, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also optimise the width of the interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd.predict_set(tau=tau, epsilon=0.1, minimise_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing exchangeability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a synhtetic dataset with a change point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = np.array([2, 1, 0, 0])\n",
    "beta2 = np.array([0, 0, 1, 2])\n",
    "\n",
    "Y1 = X[:int(N/2)] @ beta1 + rnd_gen.normal(loc=0, scale=1, size=int(N/2))\n",
    "Y2 = X[int(N/2):N] @ beta2 + rnd_gen.normal(loc=0, scale=1, size=int(N/2))\n",
    "y = np.concatenate([Y1, Y2])\n",
    "\n",
    "# Ensure that we can get informative prediction sets\n",
    "X_init_train = X[:int(np.ceil(2/epsilon))]\n",
    "y_init_train = y[:int(np.ceil(2/epsilon))]\n",
    "\n",
    "X_process = X[int(np.ceil(2/epsilon)):]\n",
    "y_process = y[int(np.ceil(2/epsilon)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp import PluginMartingale\n",
    "\n",
    "M = PluginMartingale(warnings=False) # We expect the martingale to grow, and the warnings can be supressed\n",
    "\n",
    "cp = ConformalRidgeRegressor(a=0.001)\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "# Ensure that we can get informative prediction sets\n",
    "X_init_train = X[:int(np.ceil(2/epsilon))]\n",
    "y_init_train = y[:int(np.ceil(2/epsilon))]\n",
    "\n",
    "X_process = X[int(np.ceil(2/epsilon)):]\n",
    "y_process = y[int(np.ceil(2/epsilon)):]\n",
    "\n",
    "cp.learn_initial_training_set(X_init_train, y_init_train)\n",
    "\n",
    "for obj, lab in zip(X_process, y_process):\n",
    "    \n",
    "    # Make prediction\n",
    "    Gamma, precomputed = cp.predict(obj, epsilon=epsilon, return_update=True) \n",
    "    # To avoid repeating computations, we return some precomputed arrays if return_update=True\n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(obj, lab, precomputed)\n",
    "    # We do not have to invert a matrix at each step n. The hat matrix can be efficiently updaten online using the Sherman-Morrison formula\n",
    "    \n",
    "    # Compute the smoothed p-value\n",
    "    p = cp.compute_p_value(x=obj, y=lab, smoothed=True, precomputed=precomputed)\n",
    "\n",
    "    # Update martingale\n",
    "    M.update_martingale_value(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M.log10_martingale_values, label=r'$\\log_{10}$ martingale')\n",
    "plt.axvline(int(N/2) - y_init_train.size, linestyle='--', label='Change point', color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel CRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel methods are under development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "X = rnd_gen.normal(loc=0, scale=1, size=(N, 4))\n",
    "beta = np.array([2, 1, 0, 0])\n",
    "y = (X @ beta)**3 + rnd_gen.normal(loc=0, scale=1, size=N)\n",
    "\n",
    "# Ensure that we can get informative prediction sets\n",
    "X_init_train = X[:int(np.ceil(2/epsilon))]\n",
    "y_init_train = y[:int(np.ceil(2/epsilon))]\n",
    "\n",
    "X_process = X[int(np.ceil(2/epsilon)):]\n",
    "y_process = y[int(np.ceil(2/epsilon)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_cp.regressors import KernelConformalRidgeRegressor\n",
    "from online_cp.kernels import GaussianKernel\n",
    "\n",
    "ker = GaussianKernel(1)\n",
    "\n",
    "kernel_a = 0.001\n",
    "cp = KernelConformalRidgeRegressor(a=kernel_a, kernel=ker)\n",
    "\n",
    "cp.learn_initial_training_set(X_init_train, y_init_train)\n",
    "\n",
    "metrics = Evaluation(err=Err, winkler=WinklerScore, width=Width)\n",
    "\n",
    "for obj, lab in zip(X_process, y_process):\n",
    "    # Make prediction\n",
    "    Gamma, precomputed = cp.predict(obj, epsilon=epsilon, return_update=True) \n",
    "    # To avoid repeating computations, we return some precomputed arrays if return_update=True\n",
    "\n",
    "    # Learn the label\n",
    "    cp.learn_one(obj, lab, precomputed)\n",
    "    # We do not have to invert a matrix at each step n. The hat matrix can be efficiently updaten online using the Sherman-Morrison formula\n",
    "    \n",
    "    # Update efficiency criteria\n",
    "    metrics.update(y=lab, Gamma=Gamma, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_cumulative_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online-cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
