{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the LSTM quantile regressor\n",
    "\n",
    "I think it would make sense to test agains some other quantile regressor, and I would quite like quantile-forest, or possibly catboost. The former is likely preferable due to its ease of training. The isotonic regression step should be superflous, and we could get as many quantiles as we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from scipy.optimize import minimize_scalar\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "MACHINE_EPSILON = lambda x: np.abs(x) * np.finfo(np.float64).eps\n",
    "from online_cp import PluginMartingale\n",
    "\n",
    "def utility(flex, limit, demand, flex_cost=0.1, overdraw_cost=1):\n",
    "    '''\n",
    "    Simple utility function that takes into account the possibility to buy too little flex.\n",
    "    NOTE: This is unrealistic in that we can not buy a real number of flex in practice.\n",
    "    '''\n",
    "    effective_demand = demand - flex # Are we above despide having flex?\n",
    "    effective_above = effective_demand > limit \n",
    "    above = demand > limit # Would we have been above if we did not buy flex?\n",
    "    if effective_above: # Even with flex, we are above the limit\n",
    "        u = - overdraw_cost * (effective_demand - limit) - flex_cost * flex\n",
    "    elif above: # We would have been over the limit if we had not had flex.\n",
    "        u = overdraw_cost * (demand - limit) - flex_cost * flex\n",
    "    else: # We are below no matter what.\n",
    "        u = - flex_cost * flex\n",
    "    return float(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data = 'lstm_quantile_regression.txt'\n",
    "\n",
    "df_qr = pd.read_csv(lstm_data, parse_dates=True)\n",
    "df_qr.index = pd.to_datetime(df_qr['timestamp_forecast'])\n",
    "df_qr.timestamp_start = pd.to_datetime(df_qr.timestamp_start)\n",
    "df_qr.timestamp_forecast = pd.to_datetime(df_qr.timestamp_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qr.true_target.min(), df_qr.true_target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qr['p0.01'].min(), df_qr['p0.99'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, I think 10 and 60 are reasonable bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply isontonic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 40\n",
    "df_quantiles = df_qr.drop(columns=['station', 'timestamp_start', 'timestamp_forecast', 'true_target'])\n",
    "df_quantiles.columns = sorted(df_quantiles.columns, key=lambda x: float(x[1:]))\n",
    "sorted_columns = sorted(df_quantiles.columns, key=lambda x: float(x[1:]))\n",
    "df_quantiles.columns = [float(col[1:]) for col in sorted_columns]\n",
    "\n",
    "# Apply isontonic regression to get proper quantiles\n",
    "ir = IsotonicRegression()\n",
    "for i, row in df_quantiles.iterrows():\n",
    "    ir.fit(df_quantiles.columns, row.values)\n",
    "    row[row.index] = ir.predict(df_quantiles.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write decision process for protected and basic decision process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_util(cpd, d, jump_points):\n",
    "    Delta_Q = np.array([utility(d, limit, y) * (cpd(y=y + MACHINE_EPSILON(y)) - cpd(y=y - MACHINE_EPSILON(y))) for y in jump_points])\n",
    "    return jump_points @ Delta_Q\n",
    "\n",
    "\n",
    "def expectation(cpd, jump_points):\n",
    "    Delta_Q = np.array([(cpd(y=y + MACHINE_EPSILON(y)) - cpd(y=y - MACHINE_EPSILON(y))) for y in jump_points])\n",
    "    return jump_points @ Delta_Q\n",
    "\n",
    "def make_decision(idx, B_n, lower_bound=0):\n",
    "    # Define the quantile values\n",
    "    quantiles = np.zeros(101)\n",
    "    quantiles[1:-1] = df_quantiles.iloc[idx]\n",
    "    quantiles[0] = 10 # Demand is never negative. We could probably take some safe lower bound here. NOTE: A tighter bound would be better.\n",
    "    quantiles[-1] = 55 # Make it bounded. We could take some safe upper bound here. 2*limit is arbitrary, but probably safe. NOTE: A tighter bound would be better.\n",
    "\n",
    "    # Define the probability levels corresponding to the quantiles\n",
    "    p = np.zeros(101)  # Evenly spaced probabilities\n",
    "    p[1:-1] = df_quantiles.columns\n",
    "    p[0] = 0.0\n",
    "    p[-1] = 1.0\n",
    "\n",
    "    # Sort unique quantiles and associated probabilities\n",
    "    unique_x, unique_p = np.unique(quantiles, return_index=True)\n",
    "    sorted_p = p[unique_p]\n",
    "\n",
    "    # Define exact generalized inverse (right-continuous)\n",
    "    def exact_cdf(x):\n",
    "        return sorted_p[np.searchsorted(unique_x, x, side='right') - 1]\n",
    "    \n",
    "    # Make base decision\n",
    "    cdf = lambda y: exact_cdf(y)\n",
    "\n",
    "    optimiser_decision = max(0, minimize_scalar(lambda d: -exp_util(cdf, d, unique_x), bounds=(lower_bound,10)).x)\n",
    "\n",
    "    # Make protected decision\n",
    "    protected_cdf = lambda y: B_n(exact_cdf(y))\n",
    "\n",
    "    optimiser_protected_decision = max(0, minimize_scalar(lambda d: -exp_util(protected_cdf, d, unique_x), bounds=(lower_bound,10)).x)\n",
    "\n",
    "    optimal_d = max(df_qr.iloc[idx].true_target - limit, 0)\n",
    "\n",
    "    return optimal_d, optimiser_decision, optimiser_protected_decision, cdf, protected_cdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = np.zeros(df_quantiles.shape[0])\n",
    "optimal_decisions = np.zeros_like(decisions)\n",
    "protected_decisions = np.zeros_like(decisions)\n",
    "\n",
    "pit = np.zeros_like(decisions)\n",
    "protected_pit = np.zeros_like(decisions)\n",
    "\n",
    "martingale = PluginMartingale(warnings=False)\n",
    "\n",
    "num = 700 # df_quantiles.shape[0]\n",
    "\n",
    "for idx in tqdm(range(num)):\n",
    "    optimal_d, optimiser_decision, optimiser_protected_decision, cdf, protected_cdf = make_decision(idx, martingale.B_n, lower_bound=-1)\n",
    "    decisions[idx] = optimiser_decision\n",
    "    optimal_decisions[idx] = optimal_d\n",
    "    protected_decisions[idx] = optimiser_protected_decision\n",
    "    y = df_qr.iloc[idx].true_target\n",
    "    p = cdf(y)\n",
    "    protected_p = martingale.B_n(p)\n",
    "    pit[idx] = p\n",
    "    protected_pit[idx] = protected_p\n",
    "\n",
    "    martingale.update_martingale_value(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.05\n",
    "base_decisions = (df_qr.drop(columns=['station', 'timestamp_start', 'timestamp_forecast', 'true_target'])[f'p{1-epsilon}'] - limit).clip(lower=0).values\n",
    "median_decisions = (df_qr.drop(columns=['station', 'timestamp_start', 'timestamp_forecast', 'true_target'])['p0.5'] - limit).clip(lower=0).values\n",
    "isotonic_decisions = (df_quantiles[1-epsilon] - limit).clip(lower=0).values\n",
    "\n",
    "flex_cost = 0.025 # This is the realistic one, that we were using in the paper.\n",
    "util_func = lambda d, demand: utility(d, limit, demand, flex_cost=flex_cost)\n",
    "\n",
    "Utility = np.zeros_like(decisions)\n",
    "for i, (d, demand) in enumerate(zip(decisions, df_qr.true_target.values)):\n",
    "    Utility[i] = util_func(d, demand)\n",
    "\n",
    "optimal_Utility = np.zeros_like(decisions)\n",
    "for i, (d, demand) in enumerate(zip(optimal_decisions, df_qr.true_target.values)):\n",
    "    optimal_Utility[i] = util_func(d, demand)\n",
    "\n",
    "protected_Utility = np.zeros_like(decisions)\n",
    "for i, (d, demand) in enumerate(zip(protected_decisions, df_qr.true_target.values)):\n",
    "    protected_Utility[i] = util_func(d, demand)\n",
    "\n",
    "base_Utility = np.zeros_like(decisions)\n",
    "for i, (d, demand) in enumerate(zip(base_decisions, df_qr.true_target.values)):\n",
    "    base_Utility[i] = util_func(d, demand)\n",
    "\n",
    "isotonic_Utility = np.zeros_like(decisions)\n",
    "for i, (d, demand) in enumerate(zip(isotonic_decisions, df_qr.true_target.values)):\n",
    "    isotonic_Utility[i] = util_func(d, demand)\n",
    "\n",
    "median_Utility = np.zeros_like(decisions)\n",
    "for i, (d, demand) in enumerate(zip(median_decisions, df_qr.true_target.values)):\n",
    "    median_Utility[i] = util_func(d, demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regret = optimal_Utility - Utility\n",
    "protected_Regret = optimal_Utility - protected_Utility\n",
    "base_Regret = optimal_Utility - base_Utility\n",
    "isotonic_Regret = optimal_Utility - isotonic_Utility\n",
    "median_Regret = optimal_Utility - median_Utility\n",
    "\n",
    "plt.plot(Regret.cumsum(), label='Expectation')\n",
    "plt.plot(protected_Regret.cumsum(), label=f'Protected expectation')\n",
    "plt.plot(base_Regret.cumsum(), label=f'Base confidence {1-epsilon}')\n",
    "plt.plot(isotonic_Regret.cumsum(), label=f'Isotonic confidence {1-epsilon}')\n",
    "# plt.plot(median_Regret.cumsum(), label='Median')\n",
    "plt.title('Cumulative regret')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total utility:')\n",
    "\n",
    "print(f'Optimal: {optimal_Utility.sum()}')\n",
    "print(f'Expectation: {Utility.sum()}')\n",
    "print(f'Protected expectation: {protected_Utility.sum()}')\n",
    "print(f'Base confidence {1-epsilon}: {base_Utility.sum()}')\n",
    "print(f'Isotonic confidence {1-epsilon}: {isotonic_Utility.sum()}')\n",
    "print(f'Median: {median_Utility.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of flex instances:')\n",
    "\n",
    "print(f'Optimal: {(optimal_decisions > 0).sum()}')\n",
    "print(f'Expectation: {(decisions > 0).sum()}')\n",
    "print(f'Protected expectation: {(protected_decisions > 0).sum()}')\n",
    "print(f'Base confidence {1-epsilon}: {(base_decisions > 0).sum()}')\n",
    "print(f'Isotonic confidence {1-epsilon}: {(isotonic_decisions > 0).sum()}')\n",
    "print(f'Median: {(median_decisions > 0).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of overdraws:')\n",
    "\n",
    "print(f'Optimal: {(df_qr.true_target.values - optimal_decisions > limit).sum()}')\n",
    "print(f'Expectation: {(df_qr.true_target.values - decisions > limit).sum()}')\n",
    "print(f'Protected expectation: {(df_qr.true_target.values - protected_decisions > limit).sum()}')\n",
    "print(f'Base confidence {1-epsilon}: {(df_qr.true_target.values - base_decisions > limit).sum()}')\n",
    "print(f'Isotonic confidence {1-epsilon}: {(df_qr.true_target.values - isotonic_decisions > limit).sum()}')\n",
    "print(f'Median: {(df_qr.true_target.values - median_decisions > limit).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unnecessary flex buys:')\n",
    "\n",
    "print(f'Optimal: {((df_qr.true_target < limit) & (optimal_decisions > 0)).sum()}')\n",
    "print(f'Expectation: {((df_qr.true_target < limit) & (decisions > 0)).sum()}')\n",
    "print(f'Protected expectation: {((df_qr.true_target < limit) & (protected_decisions > 0)).sum()}')\n",
    "print(f'Base confidence {1-epsilon}: {((df_qr.true_target < limit) & (base_decisions > 0)).sum()}')\n",
    "print(f'Isotonic confidence {1-epsilon}: {((df_qr.true_target < limit) & (isotonic_decisions > 0)).sum()}')\n",
    "print(f'Median: {((df_qr.true_target < limit) & (median_decisions > 0)).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total flex:')\n",
    "\n",
    "print(f'Optimal: {optimal_decisions.sum()}')\n",
    "print(f'Expectation: {decisions.sum()}')\n",
    "print(f'Protected expectation: {protected_decisions.sum()}')\n",
    "print(f'Base confidence {1-epsilon}: {base_decisions.sum()}')\n",
    "print(f'Isotonic confidence {1-epsilon}: {isotonic_decisions.sum()}')\n",
    "print(f'Median: {median_decisions.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total flex cost:')\n",
    "\n",
    "print(f'Optimal: {optimal_decisions.sum() * flex_cost}')\n",
    "print(f'Expectation: {decisions.sum() * flex_cost}')\n",
    "print(f'Protected expectation: {protected_decisions.sum() * flex_cost}')\n",
    "print(f'Base confidence {1-epsilon}: {base_decisions.sum() * flex_cost}')\n",
    "print(f'Isotonic confidence {1-epsilon}: {isotonic_decisions.sum() * flex_cost}')\n",
    "print(f'Median: {median_decisions.sum() * flex_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total overdraw cost:')\n",
    "# TODO: Figure out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pit, density=True)\n",
    "plt.hist(protected_pit, density=True, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlineCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
